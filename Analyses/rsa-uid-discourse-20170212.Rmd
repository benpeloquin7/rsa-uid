---
title: "Rsa-uid-discourse-20180212"
author: "Ben"
date: "2/12/2018"
output: html_document
---

# Contents:

(1) Single run discourse model
(2) Single run orderings models

For boostrapped Entropy decomposition see `rsa-uid-discourse-20180226.Rmd`

```{r libraries, message=FALSE, warning=FALSE}
rm(list = ls())  # clear workspace

library(doParallel)
library(dplyr)
library(entropy)
library(gganimate)
library(ggplot2)
library(ggthemes)
library(tidyr)
library(zoo)

source("run-helpers.R")
```

```{r getModel}
fPath <- '/Users/benpeloquin/Desktop/Projects/rsa_uid/Models/discourse/rsa-uid-discourse-20180215.wppl'
m <- getModelFile(fPath)
```

```{r runFn}
run <- createRunFn(m)
runFn <- function(i, targetDistr, nUtterances, resultType, alpha) {
  dTemp <- data.frame(targetDistr=targetDistr, nUtterances=nUtterances, resultType=resultType, alpha=alpha)
  df <- run(dTemp) %>%
    mutate(runNum=i, targetDistr=targetDistr, alpha=alpha, resultType=resultType)
  df
}
```

# (1) Single run models

Run functions.
```{r singleRun}
ALPHA <- 20
TOPIC <- 'T1'
NUM_UTTERANCES <- 120
df_baseline <- runFn(1, 
                     targetDistr=TOPIC, 
                     nUtterances=NUM_UTTERANCES, 
                     resultType='baseline', 
                     alpha=ALPHA)
df_contextUnwareS2 <- runFn(1, 
                            targetDistr=TOPIC, 
                            nUtterances=NUM_UTTERANCES, 
                            resultType='contextUnawareS2', 
                            alpha=ALPHA)
df_contextAwareS2 <- runFn(1, 
                           targetDistr=TOPIC, 
                           nUtterances=NUM_UTTERANCES, 
                           resultType='contextAwareS2', 
                           alpha=ALPHA)
# df_baselineReverse <- runFn(1, NUM_UTTERANCES, 'baseline', ALPHA, 'true')
# df_contextUnwareS2Reverse <- runFn(1, NUM_UTTERANCES, 'contextUnawareS2', ALPHA, 'true')
# df_contextAwareS2Reverse <- runFn(1, NUM_UTTERANCES, 'contextAwareS2', ALPHA, 'true')
# df_S1Reverse <- runFn(1, NUM_UTTERANCES, 'S1', ALPHA, 'true')

df_agg <- rbind(df_baseline, df_contextUnwareS2, df_contextAwareS2)
```

Convergence plots by speaker type.
```{r listenerInferencePlot}
df_agg %>% 
  gather(topic, listenerTopicPosterior, c(T1, T2, T3, T4)) %>%
  mutate(topic=ifelse(topic==TOPIC, 'target', topic)) %>%
  ggplot(aes(x=utteranceNum, y=listenerTopicPosterior, col=topic)) +
    geom_line() +
    # geom_vline(data=df_agg %>% select(resultType, pos) %>% unique, aes(xintercept=pos), lty=2)+
    theme_few() +
    facet_grid(~resultType)
```

Speaker utterances plot.
```{r inspectingUtterancePlot}
df_agg %>%
  mutate(utteranceVal=ifelse(utterance=='a', 1, ifelse(utterance=='b', 1, 1))) %>%
  ggplot(aes(x=utteranceNum, y=utteranceVal, col=utterance), alpha=0.6) +
    # geom_vline(data=df_agg %>% select(resultType, pos) %>% unique, aes(xintercept=pos), lty=2) +
    geom_text(aes(x=utteranceNum, label=utterance, y=utteranceVal, col=utterance)) +
    ylim(0.75, 1.25) +
    theme_few() +
    facet_wrap(~resultType, ncol=1)
```

Zoom in on first 25 utterances.
```{r first30Utterances}
df_agg %>%
  mutate(utteranceVal=0.5) %>%
  filter(utteranceNum < 25) %>%
  gather(topic, listenerTopicPosterior, c(T1, T2, T3, T4)) %>%
  ggplot(aes(x=utteranceNum, y=listenerTopicPosterior, col=topic, frame=utteranceNum)) +
    geom_text(aes(x=utteranceNum, label=utterance, y=utteranceVal, col=utterance)) +
    geom_line(alpha=0.3, size=1) +
    # geom_vline(data=df_agg %>% select(resultType, pos) %>% unique, aes(xintercept=pos), lty=2)+
    theme_few() +
    facet_wrap(~resultType)
```

Binning utterances.
```{r speakerChoicePreProcess}
binSize <- 20
breaks <- seq(0, NUM_UTTERANCES, by=binSize)

df_agg <- df_agg %>%
  mutate(bin=cut(utteranceNum, breaks=breaks, right=FALSE, include.lowest=TRUE))
bin_levels <- levels(df_agg$bin)
df_agg$binVal <- match(df_agg$bin, bin_levels)
```

Preproceesing -- fill in missing values during binning.
```{r preprocessFillMissingValues}
# Get utterance counts
df_utteranceTotals <- df_agg %>%
  group_by(resultType, binVal, utterance) %>%
  summarise(n=n()) %>%
  ungroup

# Create a data.frame to merge for place-hodlders
d_fill <- data.frame(expand.grid(resultType=unique(df_utteranceTotals$resultType), 
                                 utterance=unique(df_utteranceTotals$utterance), 
                                 binVal=unique(df_utteranceTotals$binVal))) %>%
  mutate(utterance=as.character(utterance),
         n=0)

# Run merge (see https://stackoverflow.com/questions/7735647/replacing-nas-with-latest-non-na-value)
df_agg_filled <- merge(df_utteranceTotals, d_fill, by=c('resultType', 'binVal', 'utterance'), all=TRUE) %>%
  select(resultType, binVal, utterance, resultType, n.x) %>%
  mutate(n.x=ifelse(is.na(n.x), 0, n.x),
         resultType=na.locf(resultType, fromLast=TRUE)) %>%
  rename(n=n.x)
```

Continued preprocessing.
```{r utteranceProportionsPreProcess}
# Get group totals, these are uneven, depending on cuts
df_groupTotals <- df_agg_filled %>%
  group_by(resultType, binVal) %>%
  summarize(groupTotal=sum(n))


# Create utterance proportions
df_filled_uttProbs <- left_join(df_agg_filled, df_groupTotals, by=c('resultType', 'binVal')) %>%
  mutate(prop=n/groupTotal)
# Check props are calculated correctly
# all(
#   as.list(df_filled_uttProbs %>%
#             group_by(resultType, binVal) %>%
#             summarise(s=sum(prop)) %>%
#             ungroup %>%
#             select(s))$s)
```

Single run utterance proportions plot.
```{r utteranceProportionsPlot}
df_filled_uttProbs %>%
  ggplot(aes(x=binVal, y=prop, fill=utterance)) +
    # geom_vline(data=df_agg %>% select(resultType, posBin) %>% unique, aes(xintercept=posBin), lty=2) +
    geom_bar(stat='identity', alpha=0.5) +
    facet_grid(~resultType) +
    theme_few() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Single run entropy plot.
```{r entropy1}
breaks <- seq(0, NUM_UTTERANCES, by=binSize)
# Replace with entropy.empirical()
# calcEntropy <- function(a) {
#   -1 * sum(sapply(a, function(x) {
#     log2(x) * x
#   }))
# }

df_filled_uttProbs %>%
  group_by(resultType, binVal) %>%
  summarise(entropy=entropy.empirical(n, unit=c('log2'))) %>%
  ggplot(aes(x=binVal, y=entropy)) +
    geom_line(group=1) +
    theme_few() +
    facet_grid(~resultType)
```

# (2) Optimal orderings

Orderings helpers
```{r runOrderingFns}
runOrdering <- createRunFn(mOrdering)
runOrderingFn <- function(i, nUtterances, utterancesData, alpha) {
  # dTemp <- data.frame(nUtterances=rep(nUtterances, n), utterances=utterances, alpha=rep(alpha, n))
  utterancesDataStr <- paste(utterancesData, collapse=" ")
  dTemp <- data.frame(nUtterances=nUtterances, utterancesData=utterancesDataStr, alpha=alpha)
  df <- runOrdering(dTemp) %>%
    mutate(nUtterances=nUtterances, utterances=utterancesDataStr, alpha=alpha)
  df
}
```

50 samples using "optimal" ordering chosen by model
```{r optimalOrderingSetup}
N <- 50
firstN <- as.list(df_agg %>%
  filter(resultType=='contextAwareS2', utteranceNum < N) %>%
  select(utterance))$utterance
theoreticallyPossibleOrderings <- length(letters[seq(1:6)])^N

nOptimalOrderings <- 10
optimalOrderings <- sapply(seq(1, nOptimalOrderings), FUN=function(X) {sample(firstN)}, simplify=FALSE)
optimalOrderings[[length(optimalOrderings)+1]] <- firstN

fPath <- '/Users/benpeloquin/Desktop/Projects/rsa_uid/Models/discourse/rsa-uid-discourse-optimal-ordering-20180221.wppl'
mOrdering <- getModelFile(fPath)
```

Run optimal orderings
```{r optimalOrderings-run}
alpha <- 20
df_optimal_orderings <- data.frame()
for (utteranceList in optimalOrderings) {
  curr_df <- runOrderingFn(1, N, utteranceList, alpha) %>%
    mutate(isUsed=utterances==paste(firstN, collapse=" "))
  df_optimal_orderings <- rbind(df_optimal_orderings, curr_df)
}
```

Plot optimal orderings.
```{r optimalOrderings-plot}
df_optimal_orderings %>%
  group_by(utterances) %>%
  gather(type, val, c(distrs.T1, distrs.T2, distrs.T3, distrs.T4)) %>%
  ggplot(aes(x=index, y=val, col=utterances)) +
    geom_line(size=0.75, aes(alpha=ifelse(isUsed, 1, 0.95))) +
    theme_few() +
    theme(legend.position="none") +
    facet_grid(~type)

# Is there an optimal ordering???
# firstN
# df_optimal_orderings %>%
#   filter(index==N-1) %>%
#   select(distrs.t_distr1, utterances)
```
While they all roughly converge at the same time, at any point in the first 50 utterances, one ordering may be better than the others.

### Sub-optimal orderings
```{r sub-optimal-orderings-run, eval=FALSE}
numSamples <- 20
possibleWords <- letters[seq(1, 6)]
firstNStr <- paste(firstN, collapse=" ")
possibleUtterances <- lapply(seq(1:numSamples), function(x) {paste(sample(possibleWords, N, replace=TRUE), collapse=' ')})
possibleUtterances[[length(possibleUtterances)+1]] <- firstNStr

df_orderings <- data.frame()
alpha <- 20
for (utteranceList in possibleUtterances) {
  curr_df <- runOrderingFn(1, N, utteranceList, alpha)  %>%
    mutate(isUsed=utterances==paste(firstN, collapse=" "))
  df_orderings <- rbind(df_orderings, curr_df)
}
```

```{r sub-optimal-orderings-plot, eval=FALSE}
df_orderings %>%
  group_by(utterances) %>%
  gather(type, val, c(distrs.T1, distrs.T2, distrs.T3, distrs.T4)) %>%
  ggplot(aes(x=index, y=val, col=utterances)) +
    geom_line(size=0.75, aes(alpha=ifelse(isUsed, 1, 0.4))) +
    theme_few() +
    theme(legend.position="none") +
    facet_grid(~type)
```


# Optimal orderings varying alpha.
```{r check-alpha-effect-run}
df_optimalS2_32 <-  runFn(1, TOPIC, NUM_UTTERANCES, 'contextAwareS2', 32, 'false')
df_optimalS2_16 <-  runFn(1, TOPIC, NUM_UTTERANCES, 'contextAwareS2', 16, 'false')
df_optimalS2_8 <-  runFn(1, TOPIC, NUM_UTTERANCES, 'contextAwareS2', 8, 'false')
df_optimalS2_4 <-  runFn(1, TOPIC, NUM_UTTERANCES, 'contextAwareS2', 4, 'false')
df_optimalS2_2 <-  runFn(1, TOPIC, NUM_UTTERANCES, 'contextAwareS2', 2, 'false')
```

```{r check-alpha-effect-preprocess}
fPath <- '/Users/benpeloquin/Desktop/Projects/rsa_uid/Models/discourse/rsa-uid-discourse-optimal-ordering-20180221.wppl'
mOrdering <- getModelFile(fPath)

dfs <- list(df_optimalS2_2, df_optimalS2_4, df_optimalS2_8, df_optimalS2_16, df_optimalS2_32)
res_df <- data.frame()
for (df in dfs) {
  N <- 50
  firstN <- as.list(df %>%
                      filter(utteranceNum < N) %>%
                      select(utterance))$utterance

  # Get orderings
  nOptimalOrderings <- 10
  optimalOrderings <- sapply(seq(1, nOptimalOrderings), FUN=function(X) {sample(firstN)}, simplify=FALSE)
  optimalOrderings[[length(optimalOrderings)+1]] <- firstN
  
  # Run orderings
  agg_df <- data.frame()
  for (utteranceList in optimalOrderings) {
    curr_df <- runOrderingFn(1, N, utteranceList, unique(df$alpha)) %>%
      mutate(isUsed=utterances==paste(firstN, collapse=" "))
    agg_df <- rbind(agg_df, curr_df)
  }
  res_df <- rbind(res_df, agg_df)
}
```

```{r check-alpha-effect-plot}
res_df %>%
  group_by(alpha, utterances) %>%
  gather(type, val, c(distrs.T1, distrs.T2, distrs.T3, distrs.T4)) %>%
  ggplot(aes(x=index, y=val, col=utterances)) +
    geom_line(size=0.75, aes(alpha=ifelse(isUsed, 1, 0.95))) +
    theme_few() +
    theme(legend.position="none") +
    facet_grid(alpha~type)
```

