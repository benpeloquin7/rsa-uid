// Globals

// var rData = [{
//   'nUtterances': 100,
//   'resultType': 'baseline',
//   'alpha': 10,
//   'theta': 0.1,
//   'targetDistr': 'T1'
// }]

var getRData = function(key) {
  return rData[0][key]
}


var nUtterances = getRData('nUtterances')
var resultType = getRData('resultType')
var alpha = getRData('alpha')
var theta = getRData('theta')
var targetDistr = getRData('targetDistr')

// Topics
var topicNames = ['T1', 'T2', 'T3', 'T4']
var topicNamesDistr = Categorical({vs:topicNames, ps:[1, 1, 1, 1]})
var topicNamesPrior = function() { 
  return sample(topicNamesDistr)
}

// Worlds
var worlds = [{d:'a'}, {d:'b'}, {d:'c'}, {d:'d'}]
var wordsDistr = Categorical({vs:worlds, ps:[1, 1, 1, 1]})
var worldsPrior = function() {return sample(wordsDistr)}

// Utterances
var utterances = ['a', 'b', 'c', 'd', 'x', 'y']
var utterancesDistr = Categorical({vs:utterances, ps:[1, 1, 1, 1, 1, 1]})
var utterancesPrior = function() {return sample(utterancesDistr)}

//var T1 = Categorical({vs:worlds, ps:[0.4, 0.3, 0.2, 0.1, 0.3]})
//var T2 = Categorical({vs:worlds, ps:[0.3, 0.2, 0.1, 0.4]}) 
//var T3 = Categorical({vs:worlds, ps:[0.2, 0.1, 0.4, 0.3]})
//var T4 = Categorical({vs:worlds, ps:[0.1, 0.4, 0.3, 0.2]})

// Scenario 2: shared mode, unequal variance
//var T1 = Categorical({vs:worlds, ps:[0.6, 0.25, 0.15]})
//var T2 = Categorical({vs:worlds, ps:[0.6, 0.15, 0.25]}) 
//var T3 = Categorical({vs:worlds, ps:[0.25, 0.6, 0.15]})

// Scenario 3: equal mode, unequal variance -- this is vary hard
// in fact, we see that the uncond. entropy decreases...
//var T1 = Categorical({vs:worlds, ps:[0.6, 0.25, 0.15]})
//var T2 = Categorical({vs:worlds, ps:[0.5, 0.30, 0.20]}) 
//var T3 = Categorical({vs:worlds, ps:[0.7, 0.20, 0.10]})

// Scenario 4: expanded set
var T1 = Categorical({vs:worlds, ps:[0.6, 0.25, 0.15, 0.1]})
var T2 = Categorical({vs:worlds, ps:[0.6, 0.15, 0.25, 0.1]}) 
var T3 = Categorical({vs:worlds, ps:[0.25, 0.6, 0.15, 0.1]})
var T4 = Categorical({vs:worlds, ps:[0.25, 0.1, 0.15, 0.6]})

// Scenario 5: Equillibrium1
//var T1 = Categorical({vs:worlds, ps:[0.33, 0.33, 0.33]})
//var T2 = Categorical({vs:worlds, ps:[0.4, 0.2, 0.4]}) 
//var T3 = Categorical({vs:worlds, ps:[0.2, 0.4, 0.4]})


var topicDistr = {
  'T1': T1,
  'T2': T2,
  'T3': T3,
  'T4': T4
}

var getTopicNameDistr = function(topicName) {
  return topicDistr[topicName]
}

var litMeaning = function(utterance, world) {
  return utterance == world['d']
}

var utteranceMeaning = function(utterance) {
  if (utterance == '') {
    console.log("Error on", utterance)
  }
  var lastCharIndex = utterance.length - 1
  if (utterance.includes('a')) {
    return 'a'
  } else if (utterance.includes('b')) {
    return 'b'
  } else if (utterance.includes('c')) {
    return 'c'
  } else if (utterance.includes('d')) {
    return 'd'
  } else if (utterance.includes('x')) {
    return uniformDraw(['a', 'b'])
  } else if (utterance.includes('y')) {
    return uniformDraw(['c', 'd'])
  }
  else {
    console.log("Error on", utterance)
  }
}

var sampleWorldFromTopic = function(topicName) {
  return function() {
    if (topicName == 'T1') {
      return sample(T1)
    } 
    else if (topicName == 'T2') { 
      return sample(T2)
    } 
    else if (topicName == 'T3') { 
      return sample(T3)
    } 
    else if (topicName == 'T4') { 
      return sample(T4)
    } 
    else {
      error('No topic: ', topicName)
    }
  }
}

var utteranceMaker = function(topicDistrName) {
  var world = sampleWorldFromTopic(topicDistrName)
  var utterance = utterancesPrior()
  return utterance
}

var cost = function(utterance) {
  var costs = {
    'a': 2,
    'b': 2,
    'c': 2,
    'd': 2,
    'x': 0.1,
    'y': 0.1
  }
  return utterance.split(' ').length
}

//
// Noise
//
var _removeEmptyItems = function(arr) {
  filter(function(x) {return x != ''}, arr)
}

var replaceIndex = function(arr, index, replacement) {
  return arr.slice(0, index).concat([replacement]).concat(arr.slice(index + 1, arr.length))
}
var transformUtterance = function(transformFn) {
  return function(utterance) {
      var tokens = utterance.split(' ')
      var index = sample(RandomInteger({n:tokens.length}))
      var replacement = transformFn(index)
      return _removeEmptyItems(replaceIndex(tokens, index, replacement)).join(' ')
  }  
}
var _deleteFn = function(s) {
  return ''
}
var deleteTransform = transformUtterance(_deleteFn)

var vacuousNoiseModel = function(utterance) {
  return utterance
}
var deleteNoiseModel = function(utterance) {
  return flip(theta) ? deleteTransform(utterance) : utterance
}

var decode = cache(function(utteranceProduced, noiseModel) {
  Infer({
    model() {
      var utteranceIntended = utterancesPrior()
      var noisyUtterance = noiseModel(utteranceIntended, theta)
      factor(utteranceProduced == noisyUtterance ? 0 : -Infinity)
      return utteranceIntended
    }
  })
})


var L0 = cache(function(utterance) {
  Infer({
    model() {
      var world = worldsPrior()
      var meaning = litMeaning(utteranceMeaning(utterance), world)
      factor(meaning ? 0 : -Infinity)
      return world
    }
  })
})

var S1 = cache(function(world) {
  Infer({
    model(){
      var utterance = utterancesPrior()
      var L = L0(utterance)
      factor(alpha * L.score(world))
      return utterance
    }
  })
})

var listenerTopicDistrPosterior = cache(function(observedData) {
  return Infer({method: 'enumerate'}, function() {
    var topicDistrName = topicNamesPrior()
    if (observedData != []) {
      var obsFn = function(datum){
        var world = sampleWorldFromTopic(topicDistrName)()
        condition(datum == sample(S1(world)))}
      mapData({data: observedData}, obsFn)
    }
    return topicDistrName
  })
})

var L1 = cache(function(utterance, data) {
  Infer({
    model() {
      // Sample a topic distr given prev utterances (data).
      var estTopicDistrName = sample(listenerTopicDistrPosterior(data))
      // Sample world given topic.
      var estWorld = sampleWorldFromTopic(estTopicDistrName)()
      // Literal meaning may not be necesrray depending on our factor statement.
      var meaning = litMeaning(utteranceMeaning(utterance), estWorld)
      var S = S1(estWorld)
      // Alternatively, continue the speaker reasoning here -- I tend to like this a little more
      // Than the litera meaning factorization.
      // factor(S.score(utterance))
      factor(S.score(utterance))
      // Listener jointly reasons about (meaning, topic)
      return {'estWorld': estWorld, 'estTopicDistrName': estTopicDistrName}
    }
  })
})

// S2
// ==
// S2 speaker samples utterance given topic
// 
// Paramters
// ----------
// T: str
//    topic.
// 
// Returns
// -------
// utterance
//
var S2 = cache(function(T, data) {
  Infer({
    model() {
      var world = sampleWorldFromTopic(T)()
      var utterance = utterancesPrior()
      var L = L1(utterance, data)
      factor(alpha * (L.score({'estWorld': world, 'estTopicDistrName': T}) - cost(utterance)))
      return {'utterance': utterance}
    }
  })
})

//
// Discourse speaker
// Note (BP): Would be interseting to think about this as a speaker agent
// 
var d = []
var speakerFn = function(T, d) {
  return d.concat([sample(S2(T, d))['utterance']])
}

var speakerRecurse = function(T, d, n) {
  if (n == 0) {
    return d
  } else {
    return speakerRecurse(T, speakerFn(T, d), n-1)
  }
}


//
// Helpers
//

// Generate a sequence of numbers
var plusOne = function(n) {
  return n + 1
}

// Return a sequence of numbers
var range_ = function(start, end) {
  if (start == end) {
    return end
  } else {
    return [start].concat(range_(start+1, end))
  }
}
var range = function(start, end) {
  var res = range_(start, end)
  return res.slice(0, res.length-1)
}

// Listener probability assignment to topic "T1"
var getDataSizes = function(n) {
  return range(0, n)
}
// List of slice sizes
var dataSizes = getDataSizes(nUtterances)
// A context slice is the size of the preceding words (e.g. 0-3, 0-10, 0-n)
var contextSlices = map(function(x) {return [0, x]}, dataSizes)

// getListenerInferences
// =====================
// Given a slice of speaker utterance data, return listeners state of belief
// about the intended topic distribution.
//
var getListenerInferences = function(utterances) {
  var res = map(function(x) {
    return {
      "T1": Math.exp(listenerTopicDistrPosterior(utterances.slice(x[0], x[1])).score("T1")),
      "T2": Math.exp(listenerTopicDistrPosterior(utterances.slice(x[0], x[1])).score("T2")),
      "T3": Math.exp(listenerTopicDistrPosterior(utterances.slice(x[0], x[1])).score("T3")),
      "T4": Math.exp(listenerTopicDistrPosterior(utterances.slice(x[0], x[1])).score("T4"))}
  }, contextSlices)
  return res
}


// processUtterances
// =================
// Return a list of dictionaries containing speaker utterance data
// and corresponding state of listener inferences about topics
//
var processUtterances = function(speakerData, listenerInferences) {
  var dMap = map(function(x) {
    return {
      'utteranceNum': x, 
      'utterance': speakerData[x], 
      'T1': listenerInferences[x]['T1'],
      'T2': listenerInferences[x]['T2'],
      'T3': listenerInferences[x]['T3'],
      'T4': listenerInferences[x]['T4']}
  }, dataSizes)
  return dMap
}

// runFn
// =====
// Return data of speaker utterances / listener inferences
//
// Parameters
// ----------
// resultType : str
//   One of (contextAwareSpeaker, contextUnawareSpeaker, baseline)
//
// Returns
// --------
// List of dicts
//
var runFn = function(resultType, runReverse) {
  if (resultType == 'contextAwareS2') {
    var utteranceList = speakerRecurse(targetDistr, [], nUtterances)
    var listenerInferences = getListenerInferences(utteranceList)
    return processUtterances(utteranceList, listenerInferences)
  } 
  else if (resultType == 'contextUnawareS2') {
    var utteranceList = repeat(nUtterances, function(x) { sample(S2(targetDistr, []))['utterance']})
    var listenerInferences = getListenerInferences(utteranceList)
    return processUtterances(utteranceList, listenerInferences)
  } 
  else if (resultType == 'S1') {
    var utteranceList = repeat(nUtterances, (function(x) { return sample(S1(targetDistr))}))
    var listenerInferences = getListenerInferences(utteranceList)
    return processUtterances(utteranceList, listenerInferences)
  }
  else if (resultType == 'baseline') {
    var utteranceList = repeat(nUtterances, (function(x) {utterancesPrior()}))
    var listenerInferences = getListenerInferences(utteranceList)
    return processUtterances(utteranceList, listenerInferences)
  } 
  else {
    error('Bad resultType:', resultType)
  }
}

runFn(resultType)