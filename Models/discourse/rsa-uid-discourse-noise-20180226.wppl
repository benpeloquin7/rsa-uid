/***

  rData
  alpha
  lambda
  theta
  modelName
  N

***/

/*********************/
/*********************/
/******* SETUP *******/
/*********************/
/*********************/

var getAlpha = function(rData) {
  var data = rData[0]
  return data['alpha']
}

var getLambda = function(rData) {
  var data = rData[0]
  return data['lambda']
}

var getTheta = function(rData) {
  var data = rData[0]
  return data['theta']
}

var getModelName = function(rData) {
  var data = rData[0]
  return data['modelName']
}

var getN = function(rData) {
  var data = rData[0]
  return data['n']
}

var getSpeakerInput = function(rData) {
  var data = rData[0]
  return {d: data['speakerInput']}
}

var rData = [{'alpha':10, 'lambda':1, 'modelName':'S1', 'theta':0.23, 'n':10000}]

var LAMBDA = getLambda(rData)
var ALPHA = getAlpha(rData)
var THETA = getTheta(rData)
var N = getN(rData)
var INPUT = getSpeakerInput(rData)

var utterances = ['X a', 'a', 'X b', 'b', 'X c', 'c']
var utteranceProbs = [0.5, 1, 0.5, 1, 0.5, 1]
var utterancesDistr = Categorical({vs:utterances, ps:utteranceProbs})
var utterancesPrior = function() {return sample(utterancesDistr)}

var worlds = [{d:'a'}, {d:'b'}, {d:'c'}]
var worldProbs = [1, 1, 1]
var worldsDistr = Categorical({vs:worlds, ps:worldProbs})
var worldsPrior = function() {return sample(worldsDistr)}

var topicDistr = Categorical({vs:['T1', 'T2', 'T3'], ps:[1, 1, 1]})
var T1 = Categorical({vs:worlds, ps:[1, 0.5, 0.2]})
var T2 = Categorical({vs:worlds, ps:[0.2, 1, 0.5]}) 
var T3 = Categorical({vs:worlds, ps:[0.5, 0.2, 1]})
var topics = {
  'T1': T1,
  'T2': T2,
  'T3': T3,
}
var worldsGivenTopic = function(topic) {
   return sample(topics[topic])
}

/*********************/
/*********************/
/****** MODELS *******/
/*********************/
/*********************/

// Noise
var _removeEmptyItems = function(arr) {
  filter(function(x) {return x != ''}, arr)
}

var replaceIndex = function(arr, index, replacement) {
  return arr.slice(0, index).concat([replacement]).concat(arr.slice(index + 1, arr.length))
}
var transformUtterance = function(transformFn) {
  return function(utterance) {
      var tokens = utterance.split(' ')
      var index = sample(RandomInteger({n:tokens.length}))
      var replacement = transformFn(index)
      return _removeEmptyItems(replaceIndex(tokens, index, replacement)).join(' ')
  }  
}
var _deleteFn = function(s) {
  return ''
}
var deleteTransform = transformUtterance(_deleteFn)

var vacuousNoiseModel = function(utterance) {
  return utterance
}
var deleteNoiseModel = function(utterance) {
  return flip(THETA) ? deleteTransform(utterance) : utterance
}

var decode = cache(function(utteranceProduced, noiseModel) {
  Infer({
    model() {
      var utteranceIntended = utterancesPrior()
      var noisyUtterance = noiseModel(utteranceIntended, THETA)
      factor(utteranceProduced == noisyUtterance ? 0 : -Infinity)
      return utteranceIntended
    }
  })
})

var utteranceMeaning = function(utterance) {
  if (utterance == '') {
    console.log("Error on", utterance)
  }
  var lastCharIndex = utterance.length - 1
  if (utterance.includes('a')) {
    return 'a'
  } else if (utterance.includes('b')) {
    return 'b'
  } else if (utterance.includes('c')) {
    return 'c'
  } else if (utterance.includes('d')) {
    return 'd'
  } else {
    console.log("Error on", utterance)
  }
}

var meaning = function(utterance, world) {
  var worldDim = world['d']
  return utteranceMeaning(utterance) == worldDim
}


var cost = function(utterance) {
  return utterance.split(' ').length
}


var L0 = function(producedUtterance, topic) {
  Infer({
    model() {
      var world = worldsGivenTopic(topic)
      var intendedUtterance = sample(decode(producedUtterance, deleteNoiseModel))
      var meaning = meaning(utteranceMeaning(intendedUtterance), world)
      factor(meaning ? 0 : -Infinity)
      return world
    }
  })
}


var S0Meaning = cache(function(topic) {
  Infer({
    model() {
      var estWorld = worldsGivenTopic(topic)
      var intendedUtterance = utterancesPrior()
      var producedUtterance = deleteNoiseModel(intendedUtterance)
      var L = L0(producedUtterance, topic)
      factor(ALPHA * (L.score(estWorld) - cost(intendedUtterance)/10))
      return estWorld
    }
  })
})

var S0Utterance = cache(function(topic) {
  Infer({
    model() {
      var estWorld = worldsGivenTopic(topic)
      var intendedUtterance = utterancesPrior()
      var producedUtterance = deleteNoiseModel(intendedUtterance)
      var L = L0(producedUtterance, topic)
      factor(ALPHA * (L.score(estWorld) - cost(intendedUtterance)/10))
      return intendedUtterance
    }
  })
})


var topicDistrGivenMeaningData = cache(function(observedData) {
  return Infer({method: 'enumerate'}, function() {
    var topicDistrName = sample(topicDistr)
    if (observedData != []) {
      var obsFn = function(datum){
        condition(datum['d'] == sample(S0Meaning(topicDistrName))['d'])
      }
      mapData({data: observedData}, obsFn)
    }
    return topicDistrName
  })
})

var topicDistrGivenUtteranceData = cache(function(observedData) {
  return Infer({method: 'enumerate'}, function() {
    var topicDistrName = sample(topicDistr)
    if (observedData != []) {
      var obsFn = function(datum){
        condition(datum == sample(S0Utterance(topicDistrName)))
      }
      mapData({data: observedData}, obsFn)
    }
    return topicDistrName
  })
})

var S1 = cache(function(world, topic) {
  Infer({
    model() {
      var intendedUtterance = utterancesPrior()
      var producedUtterance = deleteNoiseModel(intendedUtterance)
      var L = L0(producedUtterance, topic)
      factor(L.score(world))
      return intendedUtterance
    }
  })
})

var L1 = cache(function(producedUtterance, data) {
  Infer({
    model() {
      var estTopic = sample(topicDistrGivenUtteranceData(data))
      var estWorld = worldsGivenTopic(estTopic)
      var intendedUtterance = sample(decode(producedUtterance, deleteNoiseModel))
      var meaning = meaning(utteranceMeaning(intendedUtterance), estWorld)
      var S = S1(estWorld, estTopic)
      factor(LAMBDA * S.score(intendedUtterance))
      return {'world': estWorld, 'topic': estTopic}
    }
  })
})

var S2 = cache(function(world, topic, data) {
  Infer({
    model() {
      var intendedUtterance = utterancesPrior()
      var producedUtterance = deleteNoiseModel(intendedUtterance)
      var L = L1(producedUtterance, data)
      var res = {'world': world, 'topic': topic}
      factor(ALPHA * (L.score(res)-cost(intendedUtterance)/10))
      return {'utterance': intendedUtterance}
    }
  })
})

//
// Speaker utterance generation
//
var d = []
var speakerFn = function(T, d) {
  var world = worldsGivenTopic(T)
  return d.concat([sample(S2(world, T, d))['utterance']])
}

var speakerRecurse = function(T, d, n) {
  if (n == 0) {
    return d
  } else {
    return speakerRecurse(T, speakerFn(T, d), n-1)
  }
}

// Things to show:
// 1. Speaker should use marking to signal the topic early on
speakerRecurse('T1', [], 10)

// L1
// viz.table(marginalize(L1('X a', [{d:'c'}, {d:'a'}]), 'topic'))
// viz.table(marginalize(L1('a', [{d:'c'}, {d:'a'}]), 'topic'))
// viz.table(marginalize(L1('X b', [{d:'c'}, {d:'a'}]), 'topic'))
// viz.table(marginalize(L1('b', [{d:'c'}, {d:'a'}]), 'topic'))
// viz.table(marginalize(L1('X c', [{d:'c'}, {d:'a'}]), 'topic'))
// viz.table(marginalize(L1('c', [{d:'c'}, {d:'a'}]), 'topic'))

// var T1 = Categorical({vs:worlds, ps:[1, 0.5, 0.2]})
// var T2 = Categorical({vs:worlds, ps:[0.2, 1, 0.5]}) 
// var T3 = Categorical({vs:worlds, ps:[0.5, 0.2, 1]})