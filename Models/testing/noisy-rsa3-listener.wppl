/***

  rData
  alpha
  lambda
  theta
  modelName
  N

***/

/*********************/
/*********************/
/******* SETUP *******/
/*********************/
/*********************/

var getAlpha = function(rData) {
  var data = rData[0]
  return data['alpha']
}

var getLambda = function(rData) {
  var data = rData[0]
  return data['lambda']
}

var getTheta = function(rData) {
  var data = rData[0]
  return data['theta']
}

var getModelName = function(rData) {
  var data = rData[0]
  return data['modelName']
}

var getN = function(rData) {
  var data = rData[0]
  return data['n']
}

var getSpeakerInput = function(rData) {
  var data = rData[0]
  return {d: data['speakerInput']}
}

// var rData = [{'alpha':5, 'lambda':1, 'modelName':'S1', 'theta':0.1, 'n':10000}]

var LAMBDA = getLambda(rData)
var ALPHA = getAlpha(rData)
var THETA = getTheta(rData)
var N = getN(rData)
var INPUT = getSpeakerInput(rData)

var aUtterances = ['X a', 'a']
var bUtterances = ['X b', 'b']
var cUtterances = ['X c', 'c']
var dUtterances = ['X d', 'd']
var partialUtteranceProbs = [0.5, 1]
var aUtterancesDistr = Categorical({vs:aUtterances, ps:partialUtteranceProbs})
var bUtterancesDistr = Categorical({vs:bUtterances, ps:partialUtteranceProbs})
var cUtterancesDistr = Categorical({vs:cUtterances, ps:partialUtteranceProbs})
var dUtterancesDistr = Categorical({vs:dUtterances, ps:partialUtteranceProbs})

var utterances = ['X a', 'a', 'X b', 'b', 'X c', 'c', 'X d', 'd']
var utteranceProbs = [0.5, 1, 0.5, 1, 0.5, 1, 0.5, 1]
var utterancesDistr = Categorical({vs:utterances, ps:utteranceProbs})
var utterancesPrior = function() {return sample(utterancesDistr)}


var worlds = [{d:'a'}, {d:'b'}, {d:'c'}, {d:'d'}]
var worldProbs = [0.2, 0.5, 1, 2.5]
var worldsDistr = Categorical({vs:worlds, ps:worldProbs})
var worldsPrior = function() {return sample(worldsDistr)}

var thetaDistr = Categorical({vs: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
                              ps: [1, 1, 1, 1, 1, 1, 1, 1, 1]})
var thetaPrior = function() {return sample(thetaDistr)}

var getValidUtteranceGivenWorld = function(w) {
  return w['d'] == 'a' ? sample(aUtterancesDistr) :
         w['d'] == 'b' ? sample(bUtterancesDistr) : 
         w['d'] == 'c' ? sample(cUtterancesDistr) :
         w['d'] == 'd' ? sample(cUtterancesDistr) :
         sample(dUtterancesDistr)
}

/*********************/
/*********************/
/****** MODELS *******/
/*********************/
/*********************/

// Noise
var _removeEmptyItems = function(arr) {
  filter(function(x) {return x != ''}, arr)
}

var replaceIndex = function(arr, index, replacement) {
  return arr.slice(0, index).concat([replacement]).concat(arr.slice(index + 1, arr.length))
}
var transformUtterance = function(transformFn) {
  return function(utterance) {
      var tokens = utterance.split(' ')
      var index = sample(RandomInteger({n:tokens.length}))
      var replacement = transformFn(index)
      return _removeEmptyItems(replaceIndex(tokens, index, replacement)).join(' ')
  }  
}
var _deleteFn = function(s) {
  return ''
}
var deleteTransform = transformUtterance(_deleteFn)

var vacuousNoiseModel = function(utterance) {
  return utterance
}
var deleteNoiseModel = function(utterance, theta) {
  return flip(theta) ? deleteTransform(utterance) : utterance
}

var decode = cache(function(utteranceProduced, noiseModel, theta) {
  Infer({
    model() {
      var utteranceIntended = utterancesPrior()
      var noisyUtterance = noiseModel(utteranceIntended, theta)
      factor(utteranceProduced == noisyUtterance ? 0 : -Infinity)
      return utteranceIntended
    }
  })
})

var utteranceMeaning = function(utterance) {
  if (utterance == '') {
    console.log("Error on", utterance)
  }
  var lastCharIndex = utterance.length - 1
  if (utterance.includes('a')) {
    return 'a'
  } else if (utterance.includes('b')) {
    return 'b'
  } else if (utterance.includes('c')) {
    return 'c'
  } else if (utterance.includes('d')) {
    return 'd'
  }else {
    console.log("Error on", utterance)
  }
}


var meaning = function(utterance, world) {
  var worldDim = world['d']
  return utteranceMeaning(utterance) == worldDim
}


var L0 = cache(function(utterance, theta) {
  Infer({
    model() {
      var world = worldsPrior()
      var intendedUtterance = sample(decode(utterance, deleteNoiseModel, theta))
      var meaning = meaning(utteranceMeaning(intendedUtterance), world)
      factor(meaning ? 0 : -Infinity)
      return world
    }
  })
})

var cost = function(utterance) {
  return utterance.split(' ').length
}

var S1 = cache(function(world, theta) {
  Infer({
    model() {
      var intendedUtterance = utterancesPrior(world)
      var producedUtterance = deleteNoiseModel(intendedUtterance, theta)
      var L = L0(producedUtterance, theta)
      factor(ALPHA * (L.score(world) - cost(intendedUtterance)/10))
      return intendedUtterance
    }
  })
})

var L1 = cache(function(utterance) {
  Infer({
    model() {
      var theta = thetaPrior()
      var world = worldsPrior()
      var intendedUtterance = sample(decode(utterance, deleteNoiseModel, theta))
      var S = S1(world, theta)
      factor(LAMBDA*(S.score(intendedUtterance)))
      return world
    }
  })
})

var S2 = cache(function(world, theta) {
  Infer({
    model() {
//       var theta = thetaPrior()
      var intendedUtterance = utterancesPrior()
//       var intendedUtterance = getValidUtteranceGivenWorld(world)
      var producedUtterance = deleteNoiseModel(intendedUtterance, theta)
      var L = L1(producedUtterance, theta)
      factor(ALPHA*(L.score(world)))
      return intendedUtterance
    }
  })
})

var L2 = function(utterance, theta) {
  Infer({
    model() {
      var world = worldsPrior()
      var intendedUtterance = sample(decode(utterance, deleteNoiseModel, theta))
      var S = S2(world, theta)
      factor(LAMBDA*S.score(intendedUtterance))
      return world
    }
  })
}

var S3 = cache(function(world) {
  Infer({
    model() {
      var theta = thetaPrior()
      var intendedUtterance = getValidUtteranceGivenWorld(world)
      var producedUtterance = deleteNoiseModel(intendedUtterance, theta)
      var L = L2(producedUtterance, theta)
      factor(ALPHA * (L.score(world)-cost(intendedUtterance)/10))
      return intendedUtterance
    }
  })
})

/*********************/
/*********************/
/**** CORPUS GEN *****/
/*********************/
/*********************/

var runExperiment = function(speaker, world) {
  return sample(speaker(world))
}

var runExperiments = function(worldGenerator, speaker, n, data) {
  /*
  Parameters
  ----------
  worldGenerator: fn
    Generate a full world.
  spekeaker: fn
    RSA speaker function. Input worlds, output utterances.
  n: int
    Number of forward samples.
  data: array
    Data store (corpus).
    
  Returns
  -------
  array
    Array of utterances.
  
  */
  var world = worldGenerator()
  var currUtt = runExperiment(speaker, world)  // really this should be a dict object with context
  var success = utteranceMeaning(currUtt) == world['d']
  var currData = {currUtterance:currUtt, isSuccess:success}
  data.push(currData)
  return n <= 1 ? data : runExperiments(worldGenerator, speaker, n-1, data)
}

var worldGenerator = function() {
  /* Note that this should eventually be different from `worldsPrior`. Ideally we will have more "complex"
  worlds of (a) multiple objects and (b) objects with multiple dimensions. In the 
  single object, single object case this will look just like a single prior over a dimension.
  */
  return worldsPrior()
}

/*********************/
/*********************/
/******** run ********/
/*********************/
/*********************/

var getModel = function(modelName) {
  var models = {
    'L0': L0,
    'S1': S1,
    'L1': L1,
    'S2': S2,
    'L2': L2,
    'S3': S3
  }
  return models[modelName]
}

var modelName = getModelName(rData)
var model = getModel(modelName)
model('X')