---
title: "rsa-uid"
author: "Ben"
date: "10/30/2017"
output: html_document
---

```{r packages, warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(jsonlite)
library(rwebppl)
library(tidyr)
```

# Running Todo

* `Simulation 2` indicates that we might be able to model syntactic UID in some scenarios, perhaps meaningful disfluencies as well. 

+ Can estimate some of the hyperparameters from text (`noisePorb`, `umProb`, dimension distributions?)? (Herb Clark's um paper)

+ Can we show that the posterior mode is related to the informativity of the utterance (so as red becomes more informative the more likely we put the cue there?) Can we show it mathematically?

+ More robust data pieline

# Running experiments

* `Simulation 2`: Optional tokens in syntax. Adding an optional token (complementizer, perhaps disfluency (um)...) can provide a cue that the oncoming token(s) might be unexpected.

* `Simulation 1`: If error rate is based on signal variance can we create a speaker who prefers uniformity?

# Overview

**Question** - can we derive UID-like effects from RSA?

**Motivation** - both RSA and UID are rational accounts of communication -- describing they way optimal / near optimal interlocutors should behave. How are they connected?

#### UID
On its face UID is primarily concerned with the communicative behaviors of optimal or near optimal **speakers** attempting to convey a message through a noisy channel. We assume all communication occurs in a "noisy channel" (there are speaker mistakes, disfluencies, background noise, listener distractions, etc). Under this hypothesis, optimal speakers should try to have (1) a *constant* (uniform) rate of information in their communication signal that is (2) close to channel capacity. The purely information theoretic interpretation of UID is that this is just an optimal strategy for conveying information. A more "psychologically relevant" interpretation might interpret this as a form of *audience design* - speakers reason about what communicative signal will most likely be understood by listeners, easing the comprehension burden.

#### RSA
RSA provides a framework for formalizing both listener (understanding) and speaker (production) behavior -- as a recursive process in which listeners reason about speaker intended meanings $p_{L}(\text{meaning}|\text{utterance})$ and speakers reason about listener likely inference given some utterance $p_{S}(\text{utterance}|\text{meaning})$.

Current data observes the world `{name:'obj', size:'g', color:'r', shape:'s}` and generates utterances.

```{r load_webppl_models}
dir_path <- "/Users/benpeloquin/Desktop/Projects/rsa_uid/Models/"
baseS1 <- webppl(program_file=paste0(dir_path, 'base-S1-20171030.wppl'))
noisySigmoidS1 <- webppl(program_file=paste0(dir_path, 'noisy-sigmoid-S1-20171030.wppl'))
noisyAvgDiffS1 <- webppl(program_file=paste0(dir_path, 'noisy-avgDiff-S1-20171030.wppl'))
umModel1 <- webppl(program_file=paste0(dir_path, 'umModel-20171101.wppl'))
```

# Simulation 2: `Um Model` 

## Um model `exp1`

* `umProb` = 0.5

* `noiseProb` = 0.5

* `targetInfo` = $-log(1/length(dimension))$ (2.8)

* `target` = `{size:little, color:red, shape:triangle}`

```{r run_um_model_exp}
source('umModel20171105.R')

runExperimentWithModel <- function(model) {
  return (function(size, color, shape, umProb, noiseProb, redInfo, expNum) {
    rData <- data.frame(
      size=size,
      color=color,
      shape=shape,
      umProb=umProb,
      noiseProb=noiseProb,
      redInfo=redInfo
    )
    df <- webppl(model, data=rData, data_var="rData")
    df$size <- size
    df$color <- color
    df$shape <- shape
    df$umProb <- umProb
    df$noiseProb <- noiseProb
    df$redInfo <- redInfo
    df$expNum <- expNum
    return(df)
  })
}

runUmModel <- runExperimentWithModel(model)
```

```{r run_um_exp_1}
#colors <- c('red', 'blue', 'green', 'yellow', 'purple', 'cyan', 'black')
# size : little
# color : red
# shape : triangle
# umProb : 0.5
# noiseProb : 0.5
# target info : -log2(1 / length(colors))  --> 2.8
dfUm1 <- runUmModel('little', 'red', 'triangle', 0.5, 0.5, 1, 1)
dfUm1$support <- factor(dfUm1$support, levels=dfUm1$support[order(dfUm1$prob, decreasing=TRUE)])
```

```{r plot_um_exp1}
#ps <- c(0.5, 1, 1, 1, 1, 1, 1, 1)
#normedPS <- ps / sum(ps)
dfUm1 %>%
  mutate(plotColor=ifelse(support=='little Xred triangle', 'target', 'other')) %>%
  ggplot(aes(x=support, y=prob, fill=plotColor)) +
    geom_bar(stat='identity') +
    ggtitle("world -> {name:'obj', size:'little', color:'red', shape:'triangle'}") +
    xlab("S1 utterance") +
    ylab("p(u|m)") +
    theme_bw() +
    theme(axis.text.x=element_text(angle=90, hjust=1), 
          plot.title=element_text(hjust=0.5, size=14))
```

## Um model `exp2`

* `umProb` = 0.5

* `noiseProb` = 0.5

* `targetInfo` = 3.89

* `target` = `{size:little, color:red, shape:triangle}`

```{r run_um_exp_2}
#colors <- c('red', 'blue', 'green', 'yellow', 'purple', 'cyan', 'black')
# size : little
# color : red
# shape : triangle
# umProb : 0.5
# noiseProb : 0.5
# target info : -log2(1 / length(colors))  --> 2.8
dfUm2 <- runUmModel('little', 'red', 'triangle', 0.5, 0.5, 0.25, 1)
dfUm2$support <- factor(dfUm2$support, levels=dfUm2$support[order(dfUm2$prob, decreasing=TRUE)])
```

```{r plot_um_exp2}
dfUm2 %>%
  mutate(plotColor=ifelse(support=='little Xred triangle', 'target', 'other')) %>%
  ggplot(aes(x=support, y=prob, fill=plotColor)) +
    geom_bar(stat='identity') +
    ggtitle("world -> {name:'obj', size:'little', color:'red', shape:'triangle'}") +
    xlab("S1 utterance") +
    ylab("p(u|m)") +
    theme_bw() +
    theme(axis.text.x=element_text(angle=90, hjust=1), 
          plot.title=element_text(hjust=0.5, size=14))
```


## Um model `exp3` - varying target info
```{r um_model_exp3_run}
# Settings
targetInfos <- seq(1, 0.2, -0.2)
umProbs <- rep(0.5, length(targetInfos))
noiseProbs <- rep(0.5, length(targetInfos))
sizes <- rep('little', length(targetInfos))
shapes <- rep('triangle', length(targetInfos))
colors <- rep('red', length(targetInfos))
expNums <- 1:length(targetInfos)

# Run experiments
data <- mapply(runUmModel, 
               sizes, 
               colors, 
               shapes, 
               umProbs, 
               noiseProbs, 
               targetInfos,
               expNums, 
               SIMPLIFY=FALSE)
df <- do.call(rbind, data)
rownames(df) <- 1:nrow(df)
```

```{r um_model_exp3_plot}
focus <- c('little red triangle', 'little Xred triangle', 'Xlittle red triangle', 'little red Xtriangle')

df %>% 
  mutate(targetSurprisal=-log2(redInfo)) %>%
  filter(support %in% focus) %>%
  ggplot(aes(x=targetSurprisal, y=prob, col=support)) +
    geom_point(size=2.5) +
    geom_line(size=1.5, alpha=0.5) +
    ylab("P(u|m)") +
    xlab("-log2(p('red'))") +
    ggtitle("world -> {name:'obj', size:'little', color:'red', shape:'triangle'}") +
    theme_bw() +
    theme(plot.title=element_text(hjust=0.5, size=14))
```


```{r um_model_exp4_run}
# Settings
umProbs <- c(seq(0, 1, 0.2), seq(0, 1, 0.2))
noiseProbs <- c(seq(0, 1, 0.2), seq(1, 0, -0.2))
sizes <- rep('little', length(umProbs))
shapes <- rep('triangle', length(umProbs))
colors <- rep('red', length(umProbs))
targetInfos <- rep(1, length(umProbs))
expNums <- 1:length(umProbs)

# Run experiments
data <- mapply(runUmModel, 
               sizes, 
               colors, 
               shapes, 
               umProbs, 
               noiseProbs, 
               targetInfos,
               expNums, 
               SIMPLIFY=FALSE)
df <- do.call(rbind, data)
rownames(df) <- 1:nrow(df)
```

```{r um_model_exp4_plot}
focus <- c('little red triangle', 'little Xred triangle', 'Xlittle red triangle', 'little red Xtriangle')

df %>% 
  filter(support %in% focus) %>%
  ggplot(aes(x=paste(umProb, noiseProb), y=prob, fill=support)) +
    geom_bar(stat='identity', position='dodge') +
    theme_bw() +
    theme(axis.text.x=element_text(angle=90, hjust=1), 
          plot.title=element_text(hjust=0.5, size=14))
```

Summary:

The goal in this simulation is to reproduce syntactic UID effects. That is, given:

* RSA speaker S1 and listener L0

* utterance undergoes possible transformation through noisy model with prob `noiseProb`
  + transformation are restricted to replacements (from particular feature dimension prior).

* speaker can insert *one* semantically/syntactically vacuous item ("X") with prob `umProb`
  + inserting such a cue probabilistically reduces the chance of error for that item
  
* question - where does speaker insert the cue?
  + UID predicts that the cue should be placed before the *most* informative item.
  
Note: This model is parameterized by:

* `noiseProb`: probability that given utterance will be transformed.

* `umProb`: probability that a speaker will insert a cue.

* `targetInfo` / `dimension distributions` -- specific token informativity (relative to it's distr)


# Simulation 1: Simulating the `constant rate` part of UID.
---------

### Context
* Objects var along three dimensions `size` [big, little], `color` [red, blue] and `shape` [square, triangle].
* The language `L` available to both speaker `S` and listener `L` is redundant in that the each dimension has 4 possible ways it can be referred to. In our language both `rrrr` and `r` refer to the color `red`, however the number of repetitions encodes the informativity of that particular expression. In later simulations, we'll vary the informativity relative to the length.
  * a signal containing *'gggg r ssss'* ("big red square") is "spikier" than the equivalent *'g r s'* or *'gggg rrrr ssss'*. An optimal speaker should disprefer "spiky" utterances in favor for "smooth" ones.
* Speaker is randomly given a object to communicate about. All objects contain the three dimensions and are presented in isolation. Speaker attempts to communicate about `obj1` where `obj = {name:'obj', size:'g', color:'r', shape:'s}`.

We compare three Speaker models :

0. `baseS1`: base RSA
0. `noisySigmoidS1`: a listener may misunderstand an utterance with probability relative to the noisiness of the utterance (simple sigmoid of total noise)
0. `noisyAvgDiffS1`: a listener may misunderstand an utterance with probability relative to the noisiness of the utterance (avg noisy out of max possible)

#### Helpers

```{r helpers}
getInformativity <- function(utterances) {
  lens <- sapply(strsplit(utterances, ' '), function(x) {
    return(sapply(x, function(y) {return(nchar(y))}))
  })
  return(paste(as.character(lens[1, ]), as.character(lens[2, ]), as.character(lens[3, ])))
}

rateDiff_ <- function(a, b) {
  return(abs(a - b))
}

sigmoid <- function(x) {
  return(exp(x) / (1 + exp(x)))
}

sigmoidRateVariation <- function(infoRateStr) {
  integerRate <- sapply(strsplit(infoRateStr, ' ')[[1]], as.integer)
  totalRateVar <- (rateDiff_(integerRate[1], integerRate[2]) + rateDiff_(integerRate[2], integerRate[3]))
  rateVar <- sigmoid(totalRateVar) - 0.5
  return(rateVar)
}

avgDiffRateVariation <- function(infoRateStr) {
  integerRate <- sapply(strsplit(infoRateStr, ' ')[[1]], as.integer)
  totalRateVar <- (rateDiff_(integerRate[1], integerRate[2]) + rateDiff_(integerRate[2], integerRate[3]))
  rateVar <- totalRateVar / (3 * 2 + 1)
  return(rateVar)
}

```

#### Minimal preprocessing
```{r preprocessing}
create_preprocessed_df <- function(weppl_data, model_name, rateFn=sigmoidRateVariation, rateFnName='sigmoid') {
  df <- weppl_data
  df$infoRate <- getInformativity(as.character(df$support))
  df$rateVar <- sapply(df$infoRate, rateFn)
  df$support <- factor(df$support, levels=df$support[order(df$rateVar)])
  df$model <- model_name
  df$rateFnName <- rateFnName
  df$isConstantRate <- df$rateVar == 0
  return(df)
}
df_baseS1 <- create_preprocessed_df(baseS1, 'baseS1', avgDiffRateVariation, 'avgDiff')
df_avgDiffS1 <- create_preprocessed_df(noisyAvgDiffS1, 'noisyAvgDiffS1', avgDiffRateVariation, 'avgDiff')
df_noisySigmoidS1 <- create_preprocessed_df(noisySigmoidS1, 'noisySigmoidS1')
```

combine data
```{r}
df_combined <- rbind(df_baseS1, df_noisySigmoidS1, df_avgDiffS1)
```

## Constant information rate

### Plot: variation in signal and Speaker posterior probability of use.
```{r fig1, fig.height=8, fig.width=16, fig.align="center"}
df_combined %>%
  mutate(model=factor(model, levels=c('noisySigmoidS1', 'noisyAvgDiffS1', 'baseS1'))) %>%
  group_by(model, rateVar, rateFnName, isConstantRate) %>%
  summarise(meanProb=mean(prob),
            n=n()) %>%
  ggplot(aes(x=rateVar, y=meanProb, col=model, lty=rateFnName)) +
    geom_point(aes(size=n), alpha=0.7) +
    geom_line() +
    ggtitle("world -> {name:'obj', size:'g', color:'r', shape:'s'}") +
    xlab("variation in signal rate") +
    ylab("S1: p(u|m)") +
    theme_bw() +
    theme(text=element_text(size=16),
          axis.text.x=element_text(angle=90, hjust=1), 
          plot.title=element_text(hjust=0.5, size=24),)
```

## Plot: Speaker posterior probability for all utterances
```{r fig2, fig.height=8, fig.width=12, fig.align="center"}
df_combined %>%
  mutate(model=factor(model, levels=c('noisySigmoidS1', 'noisyAvgDiffS1', 'baseS1'))) %>%
  ggplot(aes(x=support, y=prob, fill=model)) +
    geom_bar(stat='identity') +
    facet_wrap(~model, dir='v') +
    ggtitle("world -> {name:'obj', size:'g', color:'r', shape:'s'}") +
    xlab("S1 utterance") +
    ylab("p(u|m)") +
    theme_bw() +
    theme(axis.text.x=element_text(angle=90, hjust=1), 
          plot.title=element_text(hjust=0.5, size=24)) +
    annotate("rect", xmin=0, xmax=4.5, ymin=0, ymax=0.06, fill='yellow', alpha=0.3)
```

### Take away from simulation 1

In this simulation a "UID speaker" should prefer "smooth" utterances in which the informativity is the same across the signal. So utterances like 'g r s' and 'ggg rrr sss' should be preferred to 'g rrrr s' or 'gggg r ssss'. By introducing noise into the literal meaning (the probability that the speaker will correctly interpret the utterance) we see UID-like effects in that speakers prefer "smoother" utterances. 

# Todo

* non-totally redundant semantics. `rrrr` should really be more informative that just `r`. We can say that `r` is true for any world in which `r{1,}` and `rrrr` is only true in `r{4}` worlds. Intuitively this means that `rrrr` is a stronger (more informative) expression and all the r's are scalar. Put differently, the color *dark burgundy* is a type of *red* in that a speaker could be successful in referring to a *dark burgandy* as *red*. The same may not be the case for a common red -- a speaker is less likely to be successful referring to a common red as *dark burgundy*. What if we introduce scalar semantics into the model?
* channel capacity: can we derive this from the world? That is the kind of objects we need to refer to? This also ties into having non-redundant semantics. So if we often need to talk about things that require expressive language (like `rrrr` or `bbbb` colors). This should require a "larger" channel capacity.
* elaborate on meaning noise and how this impacts literal meaning.

# Not entirely redundant semantics
```{r}
# Todo
```

# Channel capacity
```{r}
# Todo
```

