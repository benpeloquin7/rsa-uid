{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSA-UID-switchbaord\n",
    "\n",
    "Investigating (possibly) meaningful disfluencies in switchboard\n",
    "\n",
    "### Objectives\n",
    "1. analysis: do disfluencies appear before high-surprisal items?\n",
    "2. listener exp: are listeners inclined to choose high-surprisal items as good candidates when they see 'uh'\n",
    "\n",
    "### Resources\n",
    "* http://www.nltk.org/_modules/nltk/corpus/reader/switchboard.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import switchboard as sb\n",
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example discourse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourses = [d for d in sb.discourses()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<A.1: 'Uh , do you have a pet Randy ?'>,\n",
       " <B.2: 'Uh , yeah , currently we have a poodle .'>,\n",
       " <A.3: 'A poodle , miniature or , uh , full size ?'>,\n",
       " <B.4: \"Yeah , uh , it 's , uh miniature .\">,\n",
       " <A.5: 'Uh-huh .'>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discourses[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_start(s):\n",
    "    start_patt = r\"^<[AB]\\.[0-9]{1,}:\\s[\\'\\\"]\"\n",
    "    replace_patt = ''\n",
    "    s = re.sub(start_patt, replace_patt, s)\n",
    "    return s\n",
    "\n",
    "def replace_end(s):\n",
    "    end_patt = r\"\\s?\\'?>\"\n",
    "    replace_patt = ''\n",
    "    s = re.sub(end_patt, replace_patt, s)\n",
    "    return s\n",
    "\n",
    "def remove_punct(s):\n",
    "    s = re.sub('[,\\.\\?:\\{\\}\\[\\]]', '', s)\n",
    "    return s\n",
    "\n",
    "def turn2Str(t):\n",
    "    unicodeStr = t.unicode_repr()\n",
    "    s = preprocess_turn_str(unicodeStr)\n",
    "    return s\n",
    "\n",
    "def preprocess_turn_str(s):\n",
    "    s = replace_start(s)\n",
    "    s = replace_end(s)\n",
    "    s = remove_punct(s)\n",
    "    s = s.lower()\n",
    "    s = re.sub('\\s{2,}', ' ', s)\n",
    "    s = re.sub(r'\"$', '', s)\n",
    "    s = s.rstrip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<A.3: 'A poodle , miniature or , uh , full size ?'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a poodle miniature or uh full size'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exTurn = discourses[0][2]\n",
    "print(str(exTurn))\n",
    "turn2Str(exTurn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "allStrs = [turn2Str(t) for d in discourses for t in d]\n",
    "orderedTokens = ' '.join(['^ ' + s + ' $' for s in allStrs]).split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngram:\n",
    "    def __init__(self, n=2):\n",
    "        self.n = n\n",
    "        \n",
    "    def ingest(self, orderedTokens):\n",
    "        d = defaultdict(Counter)\n",
    "        for i, word in enumerate(orderedTokens):\n",
    "            if i == len(orderedTokens)-1:\n",
    "                break\n",
    "            d[word][orderedTokens[i+1]] += 1\n",
    "        self.lm = d\n",
    "        \n",
    "    def get_lm(self):\n",
    "        return self.lm\n",
    "    \n",
    "    def get_candidates(self, token):\n",
    "        return self.lm[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'apple': Counter({'on': 1, 'range': 1}),\n",
       "             'on': Counter({'the': 1}),\n",
       "             'range': Counter({'apple': 1}),\n",
       "             'the': Counter({'apple': 1})})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng = Ngram()\n",
    "exCorpus = ['apple', 'on', 'the', 'apple', 'range', 'apple']\n",
    "ng.ingest(exCorpus)\n",
    "ng.get_lm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build switchboard ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng = Ngram()\n",
    "ng.ingest(orderedTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - brainstorm\n",
    "\n",
    "* Task: sentence completion - particiants see a sentence fragment and have to fill in the missing item from a choice of five candidates. \n",
    "    + include the \"true\" candidate?\n",
    "    + include a spectrum of high->low suprisal items\n",
    "* What if we had people incrementally build sentences from the LM candidates?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = random.choice(allStrs).split(' ')\n",
    "# index = random.randint(0, len(sent))\n",
    "# sent[:index]\n",
    "exSent = 'yeah i have a uh well a mutt myself i call it a uh uh chowperd'\n",
    "exSentSplit = exSent.split(' ')\n",
    "index = random.randint(0, len(exSentSplit)-1)\n",
    "fragment = exSentSplit[:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastToken = fragment[-1]\n",
    "trueCandidate = exSentSplit[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_candidates = list(ng.get_candidates(lastToken).keys())\n",
    "candidates = set(random.sample(lm_candidates, min(5, len(lm_candidates)))) | {trueCandidate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full utterace:\tyeah i have a uh well a mutt myself i call it a uh uh chowperd\n",
      "Fragment:\tyeah i have a\n",
      "Last token:\ta\n",
      "Candidates:\t{'reporter', 'uh', 'minimum', 'belt', 'historical', 'daughter'}\n",
      "True candidate:\tuh\n"
     ]
    }
   ],
   "source": [
    "print(\"Full utterace:\\t{}\".format(exSent))\n",
    "print('Fragment:\\t{}'.format(' '.join(fragment)))\n",
    "print('Last token:\\t{}'.format(lastToken))\n",
    "print('Candidates:\\t{}'.format(candidates))\n",
    "print('True candidate:\\t{}'.format(trueCandidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "uhStrs = [s for s in allStrs if 'uh' in s.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
