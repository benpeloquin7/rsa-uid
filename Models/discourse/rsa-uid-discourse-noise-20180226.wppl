/***

  rData
  alpha
  lambda
  theta
  modelName
  N

***/

/*********************/
/*********************/
/******* SETUP *******/
/*********************/
/*********************/

var getAlpha = function(rData) {
  var data = rData[0]
  return data['alpha']
}

var getLambda = function(rData) {
  var data = rData[0]
  return data['lambda']
}

var getTheta = function(rData) {
  var data = rData[0]
  return data['theta']
}

var getModelName = function(rData) {
  var data = rData[0]
  return data['modelName']
}

var getN = function(rData) {
  var data = rData[0]
  return data['n']
}

var getSpeakerInput = function(rData) {
  var data = rData[0]
  return {d: data['speakerInput']}
}

var rData = [{'alpha':5, 'lambda':1, 'modelName':'S1', 'theta':0.4, 'n':10000}]

var LAMBDA = getLambda(rData)
var ALPHA = getAlpha(rData)
var THETA = getTheta(rData)
var N = getN(rData)
var INPUT = getSpeakerInput(rData)

var utterances = ['X a', 'a', 'X b', 'b', 'X c', 'c']
var utteranceProbs = [0.5, 1, 0.5, 1, 0.5, 1]
var utterancesDistr = Categorical({vs:utterances, ps:utteranceProbs})
var utterancesPrior = function() {return sample(utterancesDistr)}

var worlds = [{d:'a'}, {d:'b'}, {d:'c'}]
var worldProbs = [0.2, 0.5, 1]
var worldsDistr = Categorical({vs:worlds, ps:worldProbs})
var worldsPrior = function() {return sample(worldsDistr)}

var topicDistr = Categorical({vs:['T1', 'T2', 'T3'], ps:[1, 1, 1]})
var T1 = Categorical({vs:worlds, ps:[0.2, 0.5, 1]})
var T2 = Categorical({vs:worlds, ps:[0.5, 1, 0.2]}) 
var T3 = Categorical({vs:worlds, ps:[1, 0.2, 0.5]})
var topics = {
  'T1': T1,
  'T2': T2,
  'T3': T3,
}
var worldsGivenTopic = function(topic) {
   return sample(topics[topic])
}

/*********************/
/*********************/
/****** MODELS *******/
/*********************/
/*********************/

// Noise
var _removeEmptyItems = function(arr) {
  filter(function(x) {return x != ''}, arr)
}

var replaceIndex = function(arr, index, replacement) {
  return arr.slice(0, index).concat([replacement]).concat(arr.slice(index + 1, arr.length))
}
var transformUtterance = function(transformFn) {
  return function(utterance) {
      var tokens = utterance.split(' ')
      var index = sample(RandomInteger({n:tokens.length}))
      var replacement = transformFn(index)
      return _removeEmptyItems(replaceIndex(tokens, index, replacement)).join(' ')
  }  
}
var _deleteFn = function(s) {
  return ''
}
var deleteTransform = transformUtterance(_deleteFn)

var vacuousNoiseModel = function(utterance) {
  return utterance
}
var deleteNoiseModel = function(utterance) {
  return flip(THETA) ? deleteTransform(utterance) : utterance
}

var decode = cache(function(utteranceProduced, noiseModel) {
  Infer({
    model() {
      var utteranceIntended = utterancesPrior()
      var noisyUtterance = noiseModel(utteranceIntended, THETA)
      factor(utteranceProduced == noisyUtterance ? 0 : -Infinity)
      return utteranceIntended
    }
  })
})

var utteranceMeaning = function(utterance) {
  if (utterance == '') {
    console.log("Error on", utterance)
  }
  var lastCharIndex = utterance.length - 1
  if (utterance.includes('a')) {
    return 'a'
  } else if (utterance.includes('b')) {
    return 'b'
  } else if (utterance.includes('c')) {
    return 'c'
  } else if (utterance.includes('d')) {
    return 'd'
  } else {
    console.log("Error on", utterance)
  }
}


var meaning = function(utterance, world) {
  var worldDim = world['d']
  return utteranceMeaning(utterance) == worldDim
}


var L0 = cache(function(utterance, topic) {
  Infer({
    model() {
      var world = worldsGivenTopic(topic)
      var intendedUtterance = sample(decode(utterance, deleteNoiseModel))
      var meaning = meaning(utteranceMeaning(intendedUtterance), world)
      factor(meaning ? 0 : -Infinity)
      return world
    }
  })
})

var cost = function(utterance) {
  return utterance.split(' ').length
}

var S1 = cache(function(world, topic) {
  Infer({
    model() {
      var intendedUtterance = utterancesPrior()
      var producedUtterance = deleteNoiseModel(intendedUtterance)
      var L = L0(producedUtterance, topic)
      factor(ALPHA*(L.score(world) - cost(intendedUtterance)/10))
      return intendedUtterance
    }
  })
})

var topicSpeaker = cache(function(topic){
  Infer({
    model() {
      var world = worldsGivenTopic(topic)
      var intendedUtterance = utterancesPrior()
      var L = L0(intendedUtterance, topic)
      factor(L.score(world))
      return intendedUtterance
    }
  })
})

var topicDistrGivenData = cache(function(observedData) {
  return Infer({method: 'enumerate'}, function() {
    var topicDistrName = sample(topicDistr)
    if (observedData != []) {
      var obsFn = function(datum){condition(datum == sample(topicSpeaker(topicDistrName)))}
      mapData({data: observedData}, obsFn)
    }
    return topicDistrName
  })
})

var L1 = cache(function(utterance, data) {
  Infer({
    model() {
      var topic = sample(topicDistrGivenData(data))
      var world = worldsGivenTopic(topic)
      var intendedUtterance = sample(decode(utterance, deleteNoiseModel))
      var S = S1(world, topic)
      factor(20*(S.score(intendedUtterance)))
      return [world, topic]
    }
  })
})

var S2 = cache(function(world) {
  Infer({
    model() {
      var intendedUtterance = utterancesPrior()
      var producedUtterance = deleteNoiseModel(intendedUtterance)
      var L = L1(producedUtterance)
      factor(ALPHA*(L.score(world) - cost(intendedUtterance)/10))
      return intendedUtterance
    }
  })
})

// var T1 = Categorical({vs:worlds, ps:[0.2, 0.5, 1]})
// var T2 = Categorical({vs:worlds, ps:[0.5, 1, 0.2]}) 
// var T3 = Categorical({vs:worlds, ps:[1, 0.2, 0.5]}

L1('X a', ['a', 'b', 'a', 'a'])